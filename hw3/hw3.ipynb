{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1abb5ab-dd36-4b45-84ad-d2baaa6fe184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d25c8-3f5d-496b-b9f2-d2fd4017779a",
   "metadata": {},
   "source": [
    "Data are daily portfolio returns of stocks from SGX during 28 Oct 1997 through to 18 Oct 2002. The large stock portfolio returns (LSR) are simple daily ave return rates from 10 stocks viz. Singtel, UOB, DBS, OCBC, SIA, SPH, Jardine, HK Land, Great Eastern, and City Developments. The small stock portfolio returns (SSR) are simple daily ave return rates from 10 stocks viz. Econ Intl, Casa Holdings, Pertama Holdings, Meiban Group, Sunright Ltd, Armstrong Ind Corp, Penguin Boat, Freight Links Express Holdings, Liang Huat Aluminium, and Tye Soon Ltd. The market return rate is proxied by Straits Times Index return rate, STIR. d1, d2, d3, d4, d5 are dummy variables representing Monday, Tuesday, Wednesday, Thursday, and Friday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6cc7-dd30-4fd1-a720-b8ff9de7ab43",
   "metadata": {},
   "source": [
    "Perform multivariate regression and answer the following 5 Questions. Use 'from statsmodels.formula.api import ols' as a start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57359755-7da7-4438-ad4c-a8d29bef8f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days</th>\n",
       "      <th>STIR</th>\n",
       "      <th>LSR</th>\n",
       "      <th>SSR</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28/10/1997</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>-0.096719</td>\n",
       "      <td>-0.088550</td>\n",
       "      <td>-0.091323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29/10/1997</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.066769</td>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.030660</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/10/1997</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31/10/1997</th>\n",
       "      <td>Friday</td>\n",
       "      <td>0.020108</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/11/1997</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0.069216</td>\n",
       "      <td>0.057976</td>\n",
       "      <td>0.093426</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14/10/2002</th>\n",
       "      <td>Monday</td>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.007561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15/10/2002</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>0.036498</td>\n",
       "      <td>0.033885</td>\n",
       "      <td>0.046484</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/10/2002</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.007196</td>\n",
       "      <td>0.042938</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/10/2002</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>0.018568</td>\n",
       "      <td>0.019657</td>\n",
       "      <td>0.023428</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18/10/2002</th>\n",
       "      <td>Friday</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>0.050051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1299 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Days      STIR       LSR       SSR  d1  d2  d3  d4  d5\n",
       "Date                                                                   \n",
       "28/10/1997    Tuesday -0.096719 -0.088550 -0.091323   0   1   0   0   0\n",
       "29/10/1997  Wednesday  0.066769  0.053139  0.030660   0   0   1   0   0\n",
       "30/10/1997   Thursday  0.000000  0.000000  0.000000   0   0   0   1   0\n",
       "31/10/1997     Friday  0.020108  0.002225  0.015986   0   0   0   0   1\n",
       "3/11/1997      Monday  0.069216  0.057976  0.093426   1   0   0   0   0\n",
       "...               ...       ...       ...       ...  ..  ..  ..  ..  ..\n",
       "14/10/2002     Monday  0.003452  0.002468 -0.007561   1   0   0   0   0\n",
       "15/10/2002    Tuesday  0.036498  0.033885  0.046484   0   1   0   0   0\n",
       "16/10/2002  Wednesday  0.006533  0.007196  0.042938   0   0   1   0   0\n",
       "17/10/2002   Thursday  0.018568  0.019657  0.023428   0   0   0   1   0\n",
       "18/10/2002     Friday -0.003163  0.001367  0.050051   0   0   0   0   1\n",
       "\n",
       "[1299 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Large_Small_Day_of_Week.csv', index_col = 'Date').dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41466d5c-3205-4998-8f7a-463ccf720f6a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56b33d9-e084-4e1f-8361-6dbbf71485d0",
   "metadata": {},
   "source": [
    "What is the difference in mean Monday return between the large portfolio versus the small portfolio?  Find the t-statistic to test if the difference is significantly different from the null hypothesis of zero. Assume returns are normally distributed with the same variances. The means are unconditional expectations. Find the answer with the difference, the t-statistic, and the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33294485-2817-4aa7-abd7-f83010b60730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSR</th>\n",
       "      <th>SSR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3/11/1997</th>\n",
       "      <td>0.057976</td>\n",
       "      <td>0.093426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10/11/1997</th>\n",
       "      <td>0.000688</td>\n",
       "      <td>-0.022599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17/11/1997</th>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24/11/1997</th>\n",
       "      <td>0.015035</td>\n",
       "      <td>-0.021014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1/12/1997</th>\n",
       "      <td>-0.001700</td>\n",
       "      <td>-0.015981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16/9/2002</th>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.017402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23/9/2002</th>\n",
       "      <td>0.004445</td>\n",
       "      <td>-0.044629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30/9/2002</th>\n",
       "      <td>-0.022405</td>\n",
       "      <td>-0.011432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7/10/2002</th>\n",
       "      <td>0.006424</td>\n",
       "      <td>-0.023557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14/10/2002</th>\n",
       "      <td>0.002468</td>\n",
       "      <td>-0.007561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LSR       SSR\n",
       "Date                          \n",
       "3/11/1997   0.057976  0.093426\n",
       "10/11/1997  0.000688 -0.022599\n",
       "17/11/1997  0.013696  0.002207\n",
       "24/11/1997  0.015035 -0.021014\n",
       "1/12/1997  -0.001700 -0.015981\n",
       "...              ...       ...\n",
       "16/9/2002   0.001110  0.017402\n",
       "23/9/2002   0.004445 -0.044629\n",
       "30/9/2002  -0.022405 -0.011432\n",
       "7/10/2002   0.006424 -0.023557\n",
       "14/10/2002  0.002468 -0.007561\n",
       "\n",
       "[259 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = data[data['d1']==1][[\"LSR\", \"SSR\"]]\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e70d7e8-5efe-4a89-80be-d93ed69aa455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006249024521235522"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1['LSR'].mean() - q1['SSR'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1837c2c0-6074-400b-b8e3-4f207b6b3655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.436323025532494, 0.015174628227012599)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, pvalue = stats.ttest_ind(q1['LSR'], q1['SSR'], equal_var=True)\n",
    "t, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f848d28c-f3fc-4820-9e09-7f3ca44dbc14",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2819bf5f-9ed8-456c-89fa-d8d922f24e59",
   "metadata": {},
   "source": [
    "Run OLS with dependent variable LSR and explanatory variables STIR and the 5 dummy variables. Similarly run OLS with dependent variable SSR and explanatory variables STIR and the 5 dummy variables. Which of the following statement is the most accurate? (Significance level is 1%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee92d7bd-77ed-41f5-8aaa-64dc8b45a79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>LSR</td>       <th>  R-squared:         </th> <td>   0.887</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2022.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:49</td>     <th>  Log-Likelihood:    </th> <td>  4866.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1299</td>      <th>  AIC:               </th> <td>  -9722.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1293</td>      <th>  BIC:               </th> <td>  -9691.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th> <td>    0.9224</td> <td>    0.009</td> <td>  100.462</td> <td> 0.000</td> <td>    0.904</td> <td>    0.940</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>   <td>    0.0003</td> <td>    0.000</td> <td>    0.748</td> <td> 0.455</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>   <td>    0.0008</td> <td>    0.000</td> <td>    2.145</td> <td> 0.032</td> <td> 6.51e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>   <td> 7.037e-05</td> <td>    0.000</td> <td>    0.198</td> <td> 0.843</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>   <td>   -0.0001</td> <td>    0.000</td> <td>   -0.388</td> <td> 0.698</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>   <td>   -0.0002</td> <td>    0.000</td> <td>   -0.469</td> <td> 0.639</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>103.610</td> <th>  Durbin-Watson:     </th> <td>   1.906</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 469.485</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.212</td>  <th>  Prob(JB):          </th> <td>1.13e-102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.915</td>  <th>  Cond. No.          </th> <td>    25.9</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       LSR        & \\textbf{  R-squared:         } &     0.887   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.886   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2022.   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     21:07:49     & \\textbf{  Log-Likelihood:    } &    4866.9   \\\\\n",
       "\\textbf{No. Observations:} &        1299      & \\textbf{  AIC:               } &    -9722.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1293      & \\textbf{  BIC:               } &    -9691.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{STIR} &       0.9224  &        0.009     &   100.462  &         0.000        &        0.904    &        0.940     \\\\\n",
       "\\textbf{d1}   &       0.0003  &        0.000     &     0.748  &         0.455        &       -0.000    &        0.001     \\\\\n",
       "\\textbf{d2}   &       0.0008  &        0.000     &     2.145  &         0.032        &     6.51e-05    &        0.001     \\\\\n",
       "\\textbf{d3}   &    7.037e-05  &        0.000     &     0.198  &         0.843        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{d4}   &      -0.0001  &        0.000     &    -0.388  &         0.698        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{d5}   &      -0.0002  &        0.000     &    -0.469  &         0.639        &       -0.001    &        0.001     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 103.610 & \\textbf{  Durbin-Watson:     } &     1.906  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &   469.485  \\\\\n",
       "\\textbf{Skew:}          &   0.212 & \\textbf{  Prob(JB):          } & 1.13e-102  \\\\\n",
       "\\textbf{Kurtosis:}      &   5.915 & \\textbf{  Cond. No.          } &      25.9  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    LSR   R-squared:                       0.887\n",
       "Model:                            OLS   Adj. R-squared:                  0.886\n",
       "Method:                 Least Squares   F-statistic:                     2022.\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        21:07:49   Log-Likelihood:                 4866.9\n",
       "No. Observations:                1299   AIC:                            -9722.\n",
       "Df Residuals:                    1293   BIC:                            -9691.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "STIR           0.9224      0.009    100.462      0.000       0.904       0.940\n",
       "d1             0.0003      0.000      0.748      0.455      -0.000       0.001\n",
       "d2             0.0008      0.000      2.145      0.032    6.51e-05       0.001\n",
       "d3          7.037e-05      0.000      0.198      0.843      -0.001       0.001\n",
       "d4            -0.0001      0.000     -0.388      0.698      -0.001       0.001\n",
       "d5            -0.0002      0.000     -0.469      0.639      -0.001       0.001\n",
       "==============================================================================\n",
       "Omnibus:                      103.610   Durbin-Watson:                   1.906\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              469.485\n",
       "Skew:                           0.212   Prob(JB):                    1.13e-102\n",
       "Kurtosis:                       5.915   Cond. No.                         25.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "formular = 'LSR ~ STIR + d1 + d2 + d3 + d4 + d5 - 1'\n",
    "result1 = ols(formular, data).fit()\n",
    "result1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b291c7a4-efeb-4538-a682-b0b033ae5003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>SSR</td>       <th>  R-squared:         </th> <td>   0.280</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   100.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>7.37e-90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:53</td>     <th>  Log-Likelihood:    </th> <td>  3003.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1299</td>      <th>  AIC:               </th> <td>  -5995.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1293</td>      <th>  BIC:               </th> <td>  -5964.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th> <td>    0.8439</td> <td>    0.039</td> <td>   21.895</td> <td> 0.000</td> <td>    0.768</td> <td>    0.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>   <td>   -0.0061</td> <td>    0.001</td> <td>   -4.091</td> <td> 0.000</td> <td>   -0.009</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>   <td>   -0.0008</td> <td>    0.001</td> <td>   -0.520</td> <td> 0.603</td> <td>   -0.004</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>   <td>    0.0011</td> <td>    0.001</td> <td>    0.733</td> <td> 0.464</td> <td>   -0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>   <td>   -0.0004</td> <td>    0.001</td> <td>   -0.248</td> <td> 0.804</td> <td>   -0.003</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>   <td>    0.0005</td> <td>    0.001</td> <td>    0.356</td> <td> 0.722</td> <td>   -0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>148.392</td> <th>  Durbin-Watson:     </th> <td>   2.037</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1299.616</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.051</td>  <th>  Prob(JB):          </th> <td>6.19e-283</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 7.899</td>  <th>  Cond. No.          </th> <td>    25.9</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &       SSR        & \\textbf{  R-squared:         } &     0.280   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.278   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     100.8   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} &  7.37e-90   \\\\\n",
       "\\textbf{Time:}             &     21:07:53     & \\textbf{  Log-Likelihood:    } &    3003.4   \\\\\n",
       "\\textbf{No. Observations:} &        1299      & \\textbf{  AIC:               } &    -5995.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1293      & \\textbf{  BIC:               } &    -5964.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "              & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{STIR} &       0.8439  &        0.039     &    21.895  &         0.000        &        0.768    &        0.920     \\\\\n",
       "\\textbf{d1}   &      -0.0061  &        0.001     &    -4.091  &         0.000        &       -0.009    &       -0.003     \\\\\n",
       "\\textbf{d2}   &      -0.0008  &        0.001     &    -0.520  &         0.603        &       -0.004    &        0.002     \\\\\n",
       "\\textbf{d3}   &       0.0011  &        0.001     &     0.733  &         0.464        &       -0.002    &        0.004     \\\\\n",
       "\\textbf{d4}   &      -0.0004  &        0.001     &    -0.248  &         0.804        &       -0.003    &        0.003     \\\\\n",
       "\\textbf{d5}   &       0.0005  &        0.001     &     0.356  &         0.722        &       -0.002    &        0.003     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 148.392 & \\textbf{  Durbin-Watson:     } &     2.037  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } &  1299.616  \\\\\n",
       "\\textbf{Skew:}          &   0.051 & \\textbf{  Prob(JB):          } & 6.19e-283  \\\\\n",
       "\\textbf{Kurtosis:}      &   7.899 & \\textbf{  Cond. No.          } &      25.9  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                    SSR   R-squared:                       0.280\n",
       "Model:                            OLS   Adj. R-squared:                  0.278\n",
       "Method:                 Least Squares   F-statistic:                     100.8\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):           7.37e-90\n",
       "Time:                        21:07:53   Log-Likelihood:                 3003.4\n",
       "No. Observations:                1299   AIC:                            -5995.\n",
       "Df Residuals:                    1293   BIC:                            -5964.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "STIR           0.8439      0.039     21.895      0.000       0.768       0.920\n",
       "d1            -0.0061      0.001     -4.091      0.000      -0.009      -0.003\n",
       "d2            -0.0008      0.001     -0.520      0.603      -0.004       0.002\n",
       "d3             0.0011      0.001      0.733      0.464      -0.002       0.004\n",
       "d4            -0.0004      0.001     -0.248      0.804      -0.003       0.003\n",
       "d5             0.0005      0.001      0.356      0.722      -0.002       0.003\n",
       "==============================================================================\n",
       "Omnibus:                      148.392   Durbin-Watson:                   2.037\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1299.616\n",
       "Skew:                           0.051   Prob(JB):                    6.19e-283\n",
       "Kurtosis:                       7.899   Cond. No.                         25.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "formular = 'SSR ~ STIR + d1 + d2 + d3 + d4 + d5 - 1'\n",
    "result2 = ols(formular, data).fit()\n",
    "result2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3ddaae-1aac-4eec-820d-198d67376796",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bee576-9906-48be-b592-bd3453181ef5",
   "metadata": {},
   "source": [
    "Find the variances of the fitted residuals for the two regressions in Q2. Assume these variances are different. Run a GLS regression with both LSR and SSR combined as dependent variable. The explanatory variables are the same STIR and the 5 dummy variables. What is the coefficient estimate and its t-value for the Monday dummy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "98d7a655-3ba9-4992-914c-4e834e2e74ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.260183691722937e-05, 0.0005745114599180865)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_lsr = np.var(result1.resid)\n",
    "var_ssr = np.var(result2.resid)\n",
    "var_lsr, var_ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ebd716c7-b847-4b12-b800-df31fb306b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = data[[\"LSR\", \"SSR\"]]\n",
    "y = pd.concat([data[\"LSR\"],data[\"SSR\"]]).reset_index(drop=True)\n",
    "x = data[[\"STIR\", 'd1', 'd2','d3','d4','d5']]\n",
    "x1 = pd.concat([x,x]).reset_index(drop=True)\n",
    "\n",
    "x2 = sm.add_constant(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce008e1a-b9cc-46db-9ac3-0b15895d8ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GLS in module statsmodels.regression.linear_model:\n",
      "\n",
      "class GLS(RegressionModel)\n",
      " |  GLS(endog, exog, sigma=None, missing='none', hasconst=None, **kwargs)\n",
      " |\n",
      " |  Generalized Least Squares\n",
      " |\n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array_like\n",
      " |      A 1-d endogenous response variable. The dependent variable.\n",
      " |  exog : array_like\n",
      " |      A nobs x k array where `nobs` is the number of observations and `k`\n",
      " |      is the number of regressors. An intercept is not included by default\n",
      " |      and should be added by the user. See\n",
      " |      :func:`statsmodels.tools.add_constant`.\n",
      " |  sigma : scalar or array\n",
      " |      The array or scalar `sigma` is the weighting matrix of the covariance.\n",
      " |      The default is None for no scaling.  If `sigma` is a scalar, it is\n",
      " |      assumed that `sigma` is an n x n diagonal matrix with the given\n",
      " |      scalar, `sigma` as the value of each diagonal element.  If `sigma`\n",
      " |      is an n-length vector, then `sigma` is assumed to be a diagonal\n",
      " |      matrix with the given `sigma` on the diagonal.  This should be the\n",
      " |      same as WLS.\n",
      " |  missing : str\n",
      " |      Available options are 'none', 'drop', and 'raise'. If 'none', no nan\n",
      " |      checking is done. If 'drop', any observations with nans are dropped.\n",
      " |      If 'raise', an error is raised. Default is 'none'.\n",
      " |  hasconst : None or bool\n",
      " |      Indicates whether the RHS includes a user-supplied constant. If True,\n",
      " |      a constant is not checked for and k_constant is set to 1 and all\n",
      " |      result statistics are calculated as if a constant is present. If\n",
      " |      False, a constant is not checked for and k_constant is set to 0.\n",
      " |  **kwargs\n",
      " |      Extra arguments that are used to set model properties when using the\n",
      " |      formula interface.\n",
      " |\n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  pinv_wexog : ndarray\n",
      " |      `pinv_wexog` is the p x n Moore-Penrose pseudoinverse of `wexog`.\n",
      " |  cholsimgainv : ndarray\n",
      " |      The transpose of the Cholesky decomposition of the pseudoinverse.\n",
      " |  df_model : float\n",
      " |      p - 1, where p is the number of regressors including the intercept.\n",
      " |      of freedom.\n",
      " |  df_resid : float\n",
      " |      Number of observations n less the number of parameters p.\n",
      " |  llf : float\n",
      " |      The value of the likelihood function of the fitted model.\n",
      " |  nobs : float\n",
      " |      The number of observations n.\n",
      " |  normalized_cov_params : ndarray\n",
      " |      p x p array :math:`(X^{T}\\Sigma^{-1}X)^{-1}`\n",
      " |  results : RegressionResults instance\n",
      " |      A property that returns the RegressionResults class if fit.\n",
      " |  sigma : ndarray\n",
      " |      `sigma` is the n x n covariance structure of the error terms.\n",
      " |  wexog : ndarray\n",
      " |      Design matrix whitened by `cholsigmainv`\n",
      " |  wendog : ndarray\n",
      " |      Response variable whitened by `cholsigmainv`\n",
      " |\n",
      " |  See Also\n",
      " |  --------\n",
      " |  WLS : Fit a linear model using Weighted Least Squares.\n",
      " |  OLS : Fit a linear model using Ordinary Least Squares.\n",
      " |\n",
      " |  Notes\n",
      " |  -----\n",
      " |  If sigma is a function of the data making one of the regressors\n",
      " |  a constant, then the current postestimation statistics will not be correct.\n",
      " |\n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import statsmodels.api as sm\n",
      " |  >>> data = sm.datasets.longley.load()\n",
      " |  >>> data.exog = sm.add_constant(data.exog)\n",
      " |  >>> ols_resid = sm.OLS(data.endog, data.exog).fit().resid\n",
      " |  >>> res_fit = sm.OLS(ols_resid[1:], ols_resid[:-1]).fit()\n",
      " |  >>> rho = res_fit.params\n",
      " |\n",
      " |  `rho` is a consistent estimator of the correlation of the residuals from\n",
      " |  an OLS fit of the longley data.  It is assumed that this is the true rho\n",
      " |  of the AR process data.\n",
      " |\n",
      " |  >>> from scipy.linalg import toeplitz\n",
      " |  >>> order = toeplitz(np.arange(16))\n",
      " |  >>> sigma = rho**order\n",
      " |\n",
      " |  `sigma` is an n x n matrix of the autocorrelation structure of the\n",
      " |  data.\n",
      " |\n",
      " |  >>> gls_model = sm.GLS(data.endog, data.exog, sigma=sigma)\n",
      " |  >>> gls_results = gls_model.fit()\n",
      " |  >>> print(gls_results.summary())\n",
      " |\n",
      " |  Method resolution order:\n",
      " |      GLS\n",
      " |      RegressionModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      builtins.object\n",
      " |\n",
      " |  Methods defined here:\n",
      " |\n",
      " |  __init__(self, endog, exog, sigma=None, missing='none', hasconst=None, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |\n",
      " |  fit_regularized(self, method='elastic_net', alpha=0.0, L1_wt=1.0, start_params=None, profile_scale=False, refit=False, **kwargs)\n",
      " |      Return a regularized fit to a linear regression model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str\n",
      " |          Either 'elastic_net' or 'sqrt_lasso'.\n",
      " |      alpha : scalar or array_like\n",
      " |          The penalty weight.  If a scalar, the same penalty weight\n",
      " |          applies to all variables in the model.  If a vector, it\n",
      " |          must have the same length as `params`, and contains a\n",
      " |          penalty weight for each coefficient.\n",
      " |      L1_wt : scalar\n",
      " |          The fraction of the penalty given to the L1 penalty term.\n",
      " |          Must be between 0 and 1 (inclusive).  If 0, the fit is a\n",
      " |          ridge fit, if 1 it is a lasso fit.\n",
      " |      start_params : array_like\n",
      " |          Starting values for ``params``.\n",
      " |      profile_scale : bool\n",
      " |          If True the penalized fit is computed using the profile\n",
      " |          (concentrated) log-likelihood for the Gaussian model.\n",
      " |          Otherwise the fit uses the residual sum of squares.\n",
      " |      refit : bool\n",
      " |          If True, the model is refit using only the variables that\n",
      " |          have non-zero coefficients in the regularized fit.  The\n",
      " |          refitted model is not regularized.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.base.elastic_net.RegularizedResults\n",
      " |          The regularized results.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The elastic net uses a combination of L1 and L2 penalties.\n",
      " |      The implementation closely follows the glmnet package in R.\n",
      " |\n",
      " |      The function that is minimized is:\n",
      " |\n",
      " |      .. math::\n",
      " |\n",
      " |          0.5*RSS/n + alpha*((1-L1\\_wt)*|params|_2^2/2 + L1\\_wt*|params|_1)\n",
      " |\n",
      " |      where RSS is the usual regression sum of squares, n is the\n",
      " |      sample size, and :math:`|*|_1` and :math:`|*|_2` are the L1 and L2\n",
      " |      norms.\n",
      " |\n",
      " |      For WLS and GLS, the RSS is calculated using the whitened endog and\n",
      " |      exog data.\n",
      " |\n",
      " |      Post-estimation results are based on the same data used to\n",
      " |      select variables, hence may be subject to overfitting biases.\n",
      " |\n",
      " |      The elastic_net method uses the following keyword arguments:\n",
      " |\n",
      " |      maxiter : int\n",
      " |          Maximum number of iterations\n",
      " |      cnvrg_tol : float\n",
      " |          Convergence threshold for line searches\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |\n",
      " |      The square root lasso approach is a variation of the Lasso\n",
      " |      that is largely self-tuning (the optimal tuning parameter\n",
      " |      does not depend on the standard deviation of the regression\n",
      " |      errors).  If the errors are Gaussian, the tuning parameter\n",
      " |      can be taken to be\n",
      " |\n",
      " |      alpha = 1.1 * np.sqrt(n) * norm.ppf(1 - 0.05 / (2 * p))\n",
      " |\n",
      " |      where n is the sample size and p is the number of predictors.\n",
      " |\n",
      " |      The square root lasso uses the following keyword arguments:\n",
      " |\n",
      " |      zero_tol : float\n",
      " |          Coefficients below this threshold are treated as zero.\n",
      " |\n",
      " |      The cvxopt module is required to estimate model using the square root\n",
      " |      lasso.\n",
      " |\n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [*] Friedman, Hastie, Tibshirani (2008).  Regularization paths for\n",
      " |         generalized linear models via coordinate descent.  Journal of\n",
      " |         Statistical Software 33(1), 1-22 Feb 2010.\n",
      " |\n",
      " |      .. [*] A Belloni, V Chernozhukov, L Wang (2011).  Square-root Lasso:\n",
      " |         pivotal recovery of sparse signals via conic programming.\n",
      " |         Biometrika 98(4), 791-806. https://arxiv.org/pdf/1009.5689.pdf\n",
      " |\n",
      " |  hessian_factor(self, params, scale=None, observed=True)\n",
      " |      Compute weights for calculating Hessian.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameter at which Hessian is evaluated.\n",
      " |      scale : None or float\n",
      " |          If scale is None, then the default scale will be calculated.\n",
      " |          Default scale is defined by `self.scaletype` and set in fit.\n",
      " |          If scale is not None, then it is used as a fixed scale.\n",
      " |      observed : bool\n",
      " |          If True, then the observed Hessian is returned. If false then the\n",
      " |          expected information matrix is returned.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          A 1d weight vector used in the calculation of the Hessian.\n",
      " |          The hessian is obtained by `(exog.T * hessian_factor).dot(exog)`.\n",
      " |\n",
      " |  loglike(self, params)\n",
      " |      Compute the value of the Gaussian log-likelihood function at params.\n",
      " |\n",
      " |      Given the whitened design matrix, the log-likelihood is evaluated\n",
      " |      at the parameter vector `params` for the dependent variable `endog`.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      float\n",
      " |          The value of the log-likelihood function for a GLS Model.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The log-likelihood function for the normal distribution is\n",
      " |\n",
      " |      .. math:: -\\frac{n}{2}\\log\\left(\\left(Y-\\hat{Y}\\right)^{\\prime}\n",
      " |                 \\left(Y-\\hat{Y}\\right)\\right)\n",
      " |                -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
      " |                -\\frac{1}{2}\\log\\left(\\left|\\Sigma\\right|\\right)\n",
      " |\n",
      " |      Y and Y-hat are whitened.\n",
      " |\n",
      " |  whiten(self, x)\n",
      " |      GLS whiten method.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      x : array_like\n",
      " |          Data to be whitened.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The value np.dot(cholsigmainv,X).\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      GLS : Fit a linear model using Generalized Least Squares.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from RegressionModel:\n",
      " |\n",
      " |  fit(self, method: \"Literal['pinv', 'qr']\" = 'pinv', cov_type: \"Literal['nonrobust', 'fixed scale', 'HC0', 'HC1', 'HC2', 'HC3', 'HAC', 'hac-panel', 'hac-groupsum', 'cluster']\" = 'nonrobust', cov_kwds=None, use_t: 'bool | None' = None, **kwargs)\n",
      " |      Full fit of the model.\n",
      " |\n",
      " |      The results include an estimate of covariance matrix, (whitened)\n",
      " |      residuals and an estimate of scale.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      method : str, optional\n",
      " |          Can be \"pinv\", \"qr\".  \"pinv\" uses the Moore-Penrose pseudoinverse\n",
      " |          to solve the least squares problem. \"qr\" uses the QR\n",
      " |          factorization.\n",
      " |      cov_type : str, optional\n",
      " |          See `regression.linear_model.RegressionResults` for a description\n",
      " |          of the available covariance estimators.\n",
      " |      cov_kwds : list or None, optional\n",
      " |          See `linear_model.RegressionResults.get_robustcov_results` for a\n",
      " |          description required keywords for alternative covariance\n",
      " |          estimators.\n",
      " |      use_t : bool, optional\n",
      " |          Flag indicating to use the Student's t distribution when computing\n",
      " |          p-values.  Default behavior depends on cov_type. See\n",
      " |          `linear_model.RegressionResults.get_robustcov_results` for\n",
      " |          implementation details.\n",
      " |      **kwargs\n",
      " |          Additional keyword arguments that contain information used when\n",
      " |          constructing a model using the formula interface.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      RegressionResults\n",
      " |          The model estimation results.\n",
      " |\n",
      " |      See Also\n",
      " |      --------\n",
      " |      RegressionResults\n",
      " |          The results container.\n",
      " |      RegressionResults.get_robustcov_results\n",
      " |          A method to change the covariance estimator used when fitting the\n",
      " |          model.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      The fit method uses the pseudoinverse of the design/exogenous variables\n",
      " |      to solve the least squares minimization.\n",
      " |\n",
      " |  get_distribution(self, params, scale, exog=None, dist_class=None)\n",
      " |      Construct a random number generator for the predictive distribution.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          The model parameters (regression coefficients).\n",
      " |      scale : scalar\n",
      " |          The variance parameter.\n",
      " |      exog : array_like\n",
      " |          The predictor variable matrix.\n",
      " |      dist_class : class\n",
      " |          A random number generator class.  Must take 'loc' and 'scale'\n",
      " |          as arguments and return a random number generator implementing\n",
      " |          an ``rvs`` method for simulating random values. Defaults to normal.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      gen\n",
      " |          Frozen random number generator object with mean and variance\n",
      " |          determined by the fitted linear model.  Use the ``rvs`` method\n",
      " |          to generate random values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      Due to the behavior of ``scipy.stats.distributions objects``,\n",
      " |      the returned random number generator must be called with\n",
      " |      ``gen.rvs(n)`` where ``n`` is the number of observations in\n",
      " |      the data set used to fit the model.  If any other value is\n",
      " |      used for ``n``, misleading results will be produced.\n",
      " |\n",
      " |  initialize(self)\n",
      " |      Initialize model components.\n",
      " |\n",
      " |  predict(self, params, exog=None)\n",
      " |      Return linear predicted values from a design matrix.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array_like\n",
      " |          Parameters of a linear model.\n",
      " |      exog : array_like, optional\n",
      " |          Design / exogenous data. Model exog is used if None.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      array_like\n",
      " |          An array of fitted values.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      If the model has not yet been fit, params is not optional.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from RegressionModel:\n",
      " |\n",
      " |  df_model\n",
      " |      The model degree of freedom.\n",
      " |\n",
      " |      The dof is defined as the rank of the regressor matrix minus 1 if a\n",
      " |      constant is included.\n",
      " |\n",
      " |  df_resid\n",
      " |      The residual degree of freedom.\n",
      " |\n",
      " |      The dof is defined as the number of observations minus the rank of\n",
      " |      the regressor matrix.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |\n",
      " |  hessian(self, params)\n",
      " |      The Hessian matrix of the model.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The hessian evaluated at the parameters.\n",
      " |\n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model.\n",
      " |\n",
      " |      Returns -1 * Hessian of the log-likelihood evaluated at params.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The model parameters.\n",
      " |\n",
      " |  score(self, params)\n",
      " |      Score vector of model.\n",
      " |\n",
      " |      The gradient of logL with respect to each parameter.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : ndarray\n",
      " |          The parameters to use when evaluating the Hessian.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      ndarray\n",
      " |          The score vector evaluated at the parameters.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  from_formula(formula, data, subset=None, drop_cols=None, *args, **kwargs) from builtins.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model.\n",
      " |      data : array_like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array_like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`.\n",
      " |      drop_cols : array_like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      *args\n",
      " |          Additional positional argument that are passed to the model.\n",
      " |      **kwargs\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |\n",
      " |      Returns\n",
      " |      -------\n",
      " |      model\n",
      " |          The model instance.\n",
      " |\n",
      " |      Notes\n",
      " |      -----\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  endog_names\n",
      " |      Names of endogenous variables.\n",
      " |\n",
      " |  exog_names\n",
      " |      Names of exogenous variables.\n",
      " |\n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |\n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |\n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.GLS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271034aa-ef8a-43d8-bc5b-0f502b3c3745",
   "metadata": {},
   "source": [
    "## method1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40e235b2-257b-4791-8997-3b275598daed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.326</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.325</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   251.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>3.43e-219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:08:08</td>     <th>  Log-Likelihood:    </th>  <td>  5953.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2598</td>      <th>  AIC:               </th> <td>-1.189e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2592</td>      <th>  BIC:               </th> <td>-1.186e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -2.061</td> <td> 0.039</td> <td>   -0.001</td> <td>-3.57e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th>  <td>    0.8590</td> <td>    0.025</td> <td>   34.818</td> <td> 0.000</td> <td>    0.811</td> <td>    0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>    <td>   -0.0042</td> <td>    0.001</td> <td>   -4.838</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>    <td>    0.0003</td> <td>    0.001</td> <td>    0.297</td> <td> 0.767</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>    <td>    0.0016</td> <td>    0.001</td> <td>    1.902</td> <td> 0.057</td> <td>-5.06e-05</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>    <td>    0.0004</td> <td>    0.001</td> <td>    0.477</td> <td> 0.634</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>    <td>    0.0011</td> <td>    0.001</td> <td>    1.319</td> <td> 0.187</td> <td>   -0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>519.234</td> <th>  Durbin-Watson:     </th> <td>   2.034</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>16505.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.005</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.348</td>  <th>  Cond. No.          </th> <td>2.40e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.02e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.326   \\\\\n",
       "\\textbf{Model:}            &       GLS        & \\textbf{  Adj. R-squared:    } &     0.325   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     251.0   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} & 3.43e-219   \\\\\n",
       "\\textbf{Time:}             &     21:08:08     & \\textbf{  Log-Likelihood:    } &    5953.5   \\\\\n",
       "\\textbf{No. Observations:} &        2598      & \\textbf{  AIC:               } & -1.189e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &        2592      & \\textbf{  BIC:               } & -1.186e+04  \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.0007  &        0.000     &    -2.061  &         0.039        &       -0.001    &    -3.57e-05     \\\\\n",
       "\\textbf{STIR}  &       0.8590  &        0.025     &    34.818  &         0.000        &        0.811    &        0.907     \\\\\n",
       "\\textbf{d1}    &      -0.0042  &        0.001     &    -4.838  &         0.000        &       -0.006    &       -0.002     \\\\\n",
       "\\textbf{d2}    &       0.0003  &        0.001     &     0.297  &         0.767        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{d3}    &       0.0016  &        0.001     &     1.902  &         0.057        &    -5.06e-05    &        0.003     \\\\\n",
       "\\textbf{d4}    &       0.0004  &        0.001     &     0.477  &         0.634        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{d5}    &       0.0011  &        0.001     &     1.319  &         0.187        &       -0.001    &        0.003     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 519.234 & \\textbf{  Durbin-Watson:     } &     2.034  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 16505.757  \\\\\n",
       "\\textbf{Skew:}          &  -0.005 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  15.348 & \\textbf{  Cond. No.          } &  2.40e+15  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 8.02e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.326\n",
       "Model:                            GLS   Adj. R-squared:                  0.325\n",
       "Method:                 Least Squares   F-statistic:                     251.0\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):          3.43e-219\n",
       "Time:                        21:08:08   Log-Likelihood:                 5953.5\n",
       "No. Observations:                2598   AIC:                        -1.189e+04\n",
       "Df Residuals:                    2592   BIC:                        -1.186e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0007      0.000     -2.061      0.039      -0.001   -3.57e-05\n",
       "STIR           0.8590      0.025     34.818      0.000       0.811       0.907\n",
       "d1            -0.0042      0.001     -4.838      0.000      -0.006      -0.002\n",
       "d2             0.0003      0.001      0.297      0.767      -0.001       0.002\n",
       "d3             0.0016      0.001      1.902      0.057   -5.06e-05       0.003\n",
       "d4             0.0004      0.001      0.477      0.634      -0.001       0.002\n",
       "d5             0.0011      0.001      1.319      0.187      -0.001       0.003\n",
       "==============================================================================\n",
       "Omnibus:                      519.234   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16505.757\n",
       "Skew:                          -0.005   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.348   Cond. No.                     2.40e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.02e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma1 = 1/np.array([np.sqrt(var_lsr) if i < len(y)/2 else np.sqrt(var_ssr) for i in range(len(y))])\n",
    "\n",
    "gls_model = sm.GLS(y, x2, sigma=sigma1)\n",
    "res = gls_model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd1bc0-3b79-46df-a77f-4e913ab212aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## method2:wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "661b2bf0-f971-44be-9431-bfa10e91ded8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.292</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.291</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   213.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>2.63e-191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:11</td>     <th>  Log-Likelihood:    </th>  <td>  5038.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2598</td>      <th>  AIC:               </th> <td>-1.006e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2592</td>      <th>  BIC:               </th> <td>-1.003e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0009</td> <td>    0.000</td> <td>   -2.305</td> <td> 0.021</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th>  <td>    0.8481</td> <td>    0.027</td> <td>   31.960</td> <td> 0.000</td> <td>    0.796</td> <td>    0.900</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>    <td>   -0.0049</td> <td>    0.001</td> <td>   -5.296</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>    <td>    0.0002</td> <td>    0.001</td> <td>    0.206</td> <td> 0.837</td> <td>   -0.002</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>    <td>    0.0019</td> <td>    0.001</td> <td>    2.083</td> <td> 0.037</td> <td>    0.000</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>    <td>    0.0005</td> <td>    0.001</td> <td>    0.570</td> <td> 0.569</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>    <td>    0.0014</td> <td>    0.001</td> <td>    1.493</td> <td> 0.136</td> <td>   -0.000</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>526.988</td> <th>  Durbin-Watson:     </th> <td>   2.036</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>17417.202</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.037</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.684</td>  <th>  Cond. No.          </th> <td>4.09e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.65e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.292   \\\\\n",
       "\\textbf{Model:}            &       GLS        & \\textbf{  Adj. R-squared:    } &     0.291   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     213.8   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} & 2.63e-191   \\\\\n",
       "\\textbf{Time:}             &     21:07:11     & \\textbf{  Log-Likelihood:    } &    5038.2   \\\\\n",
       "\\textbf{No. Observations:} &        2598      & \\textbf{  AIC:               } & -1.006e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &        2592      & \\textbf{  BIC:               } & -1.003e+04  \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.0009  &        0.000     &    -2.305  &         0.021        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{STIR}  &       0.8481  &        0.027     &    31.960  &         0.000        &        0.796    &        0.900     \\\\\n",
       "\\textbf{d1}    &      -0.0049  &        0.001     &    -5.296  &         0.000        &       -0.007    &       -0.003     \\\\\n",
       "\\textbf{d2}    &       0.0002  &        0.001     &     0.206  &         0.837        &       -0.002    &        0.002     \\\\\n",
       "\\textbf{d3}    &       0.0019  &        0.001     &     2.083  &         0.037        &        0.000    &        0.004     \\\\\n",
       "\\textbf{d4}    &       0.0005  &        0.001     &     0.570  &         0.569        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{d5}    &       0.0014  &        0.001     &     1.493  &         0.136        &       -0.000    &        0.003     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 526.988 & \\textbf{  Durbin-Watson:     } &     2.036  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 17417.202  \\\\\n",
       "\\textbf{Skew:}          &   0.037 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  15.684 & \\textbf{  Cond. No.          } &  4.09e+15  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 5.65e-32. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.292\n",
       "Model:                            GLS   Adj. R-squared:                  0.291\n",
       "Method:                 Least Squares   F-statistic:                     213.8\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):          2.63e-191\n",
       "Time:                        21:07:11   Log-Likelihood:                 5038.2\n",
       "No. Observations:                2598   AIC:                        -1.006e+04\n",
       "Df Residuals:                    2592   BIC:                        -1.003e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0009      0.000     -2.305      0.021      -0.002      -0.000\n",
       "STIR           0.8481      0.027     31.960      0.000       0.796       0.900\n",
       "d1            -0.0049      0.001     -5.296      0.000      -0.007      -0.003\n",
       "d2             0.0002      0.001      0.206      0.837      -0.002       0.002\n",
       "d3             0.0019      0.001      2.083      0.037       0.000       0.004\n",
       "d4             0.0005      0.001      0.570      0.569      -0.001       0.002\n",
       "d5             0.0014      0.001      1.493      0.136      -0.000       0.003\n",
       "==============================================================================\n",
       "Omnibus:                      526.988   Durbin-Watson:                   2.036\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            17417.202\n",
       "Skew:                           0.037   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.684   Cond. No.                     4.09e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.65e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma2 = 1/np.array([var_lsr if i < len(y)/2 else var_ssr for i in range(len(y))])\n",
    "\n",
    "gls_model = sm.GLS(y, x2, sigma=sigma2)\n",
    "res = gls_model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a03ac6-f1e8-4e31-9199-1bf1e39e4768",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## method3:wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f9a85da2-8917-4457-b681-3eea1b7cbeda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.998</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>2.378e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:26</td>     <th>  Log-Likelihood:    </th>  <td>  6808.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2598</td>      <th>  AIC:               </th> <td>-1.361e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2592</td>      <th>  BIC:               </th> <td>-1.357e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0001</td> <td> 1.97e-05</td> <td>   -5.098</td> <td> 0.000</td> <td>   -0.000</td> <td>-6.19e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th>  <td>    0.8395</td> <td>    0.001</td> <td> 1086.719</td> <td> 0.000</td> <td>    0.838</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>    <td>    0.0001</td> <td> 3.95e-05</td> <td>    3.364</td> <td> 0.001</td> <td> 5.54e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>    <td>   -0.0005</td> <td> 2.12e-05</td> <td>  -24.992</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>    <td>-6.046e-05</td> <td> 3.84e-05</td> <td>   -1.573</td> <td> 0.116</td> <td>   -0.000</td> <td> 1.49e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>    <td>    0.0002</td> <td>  6.4e-05</td> <td>    2.412</td> <td> 0.016</td> <td> 2.89e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>    <td>    0.0002</td> <td> 6.09e-05</td> <td>    3.314</td> <td> 0.001</td> <td> 8.23e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>4009.051</td> <th>  Durbin-Watson:     </th>  <td>   1.853</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>9260885.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td>-8.848</td>  <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td>294.955</td> <th>  Cond. No.          </th>  <td>7.35e+15</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 5.6e-21. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &      0.998   \\\\\n",
       "\\textbf{Model:}            &       GLS        & \\textbf{  Adj. R-squared:    } &      0.998   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &  2.378e+05   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} &      0.00    \\\\\n",
       "\\textbf{Time:}             &     21:07:26     & \\textbf{  Log-Likelihood:    } &     6808.8   \\\\\n",
       "\\textbf{No. Observations:} &        2598      & \\textbf{  AIC:               } &  -1.361e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &        2592      & \\textbf{  BIC:               } &  -1.357e+04  \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &              \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &              \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.0001  &     1.97e-05     &    -5.098  &         0.000        &       -0.000    &    -6.19e-05     \\\\\n",
       "\\textbf{STIR}  &       0.8395  &        0.001     &  1086.719  &         0.000        &        0.838    &        0.841     \\\\\n",
       "\\textbf{d1}    &       0.0001  &     3.95e-05     &     3.364  &         0.001        &     5.54e-05    &        0.000     \\\\\n",
       "\\textbf{d2}    &      -0.0005  &     2.12e-05     &   -24.992  &         0.000        &       -0.001    &       -0.000     \\\\\n",
       "\\textbf{d3}    &   -6.046e-05  &     3.84e-05     &    -1.573  &         0.116        &       -0.000    &     1.49e-05     \\\\\n",
       "\\textbf{d4}    &       0.0002  &      6.4e-05     &     2.412  &         0.016        &     2.89e-05    &        0.000     \\\\\n",
       "\\textbf{d5}    &       0.0002  &     6.09e-05     &     3.314  &         0.001        &     8.23e-05    &        0.000     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 4009.051 & \\textbf{  Durbin-Watson:     } &      1.853   \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 9260885.145  \\\\\n",
       "\\textbf{Skew:}          &  -8.848  & \\textbf{  Prob(JB):          } &       0.00   \\\\\n",
       "\\textbf{Kurtosis:}      & 294.955  & \\textbf{  Cond. No.          } &   7.35e+15   \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 5.6e-21. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.998\n",
       "Model:                            GLS   Adj. R-squared:                  0.998\n",
       "Method:                 Least Squares   F-statistic:                 2.378e+05\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        21:07:26   Log-Likelihood:                 6808.8\n",
       "No. Observations:                2598   AIC:                        -1.361e+04\n",
       "Df Residuals:                    2592   BIC:                        -1.357e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0001   1.97e-05     -5.098      0.000      -0.000   -6.19e-05\n",
       "STIR           0.8395      0.001   1086.719      0.000       0.838       0.841\n",
       "d1             0.0001   3.95e-05      3.364      0.001    5.54e-05       0.000\n",
       "d2            -0.0005   2.12e-05    -24.992      0.000      -0.001      -0.000\n",
       "d3         -6.046e-05   3.84e-05     -1.573      0.116      -0.000    1.49e-05\n",
       "d4             0.0002    6.4e-05      2.412      0.016    2.89e-05       0.000\n",
       "d5             0.0002   6.09e-05      3.314      0.001    8.23e-05       0.000\n",
       "==============================================================================\n",
       "Omnibus:                     4009.051   Durbin-Watson:                   1.853\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          9260885.145\n",
       "Skew:                          -8.848   Prob(JB):                         0.00\n",
       "Kurtosis:                     294.955   Cond. No.                     7.35e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 5.6e-21. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma3 = np.diag(pd.concat([result1.resid**2, result2.resid**2]))\n",
    "gls_model = sm.GLS(y, x2, sigma=sigma3)\n",
    "res = gls_model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b8379-2d07-46ed-9067-e21077fcf3c0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## method4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d4ccd1e2-a95a-4e37-92d4-b3fa780cb457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.326</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.325</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   251.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>  <td>3.43e-219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:07:36</td>     <th>  Log-Likelihood:    </th>  <td>  5953.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2598</td>      <th>  AIC:               </th> <td>-1.189e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2592</td>      <th>  BIC:               </th> <td>-1.186e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -0.0007</td> <td>    0.000</td> <td>   -2.061</td> <td> 0.039</td> <td>   -0.001</td> <td>-3.57e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th>  <td>    0.8590</td> <td>    0.025</td> <td>   34.818</td> <td> 0.000</td> <td>    0.811</td> <td>    0.907</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>    <td>   -0.0042</td> <td>    0.001</td> <td>   -4.838</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>    <td>    0.0003</td> <td>    0.001</td> <td>    0.297</td> <td> 0.767</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>    <td>    0.0016</td> <td>    0.001</td> <td>    1.902</td> <td> 0.057</td> <td>-5.06e-05</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>    <td>    0.0004</td> <td>    0.001</td> <td>    0.477</td> <td> 0.634</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>    <td>    0.0011</td> <td>    0.001</td> <td>    1.319</td> <td> 0.187</td> <td>   -0.001</td> <td>    0.003</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>519.234</td> <th>  Durbin-Watson:     </th> <td>   2.034</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>16505.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.005</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>15.348</td>  <th>  Cond. No.          </th> <td>2.38e+15</td> \n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 8.16e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.326   \\\\\n",
       "\\textbf{Model:}            &       GLS        & \\textbf{  Adj. R-squared:    } &     0.325   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     251.0   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} & 3.43e-219   \\\\\n",
       "\\textbf{Time:}             &     21:07:36     & \\textbf{  Log-Likelihood:    } &    5953.5   \\\\\n",
       "\\textbf{No. Observations:} &        2598      & \\textbf{  AIC:               } & -1.189e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &        2592      & \\textbf{  BIC:               } & -1.186e+04  \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &      -0.0007  &        0.000     &    -2.061  &         0.039        &       -0.001    &    -3.57e-05     \\\\\n",
       "\\textbf{STIR}  &       0.8590  &        0.025     &    34.818  &         0.000        &        0.811    &        0.907     \\\\\n",
       "\\textbf{d1}    &      -0.0042  &        0.001     &    -4.838  &         0.000        &       -0.006    &       -0.002     \\\\\n",
       "\\textbf{d2}    &       0.0003  &        0.001     &     0.297  &         0.767        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{d3}    &       0.0016  &        0.001     &     1.902  &         0.057        &    -5.06e-05    &        0.003     \\\\\n",
       "\\textbf{d4}    &       0.0004  &        0.001     &     0.477  &         0.634        &       -0.001    &        0.002     \\\\\n",
       "\\textbf{d5}    &       0.0011  &        0.001     &     1.319  &         0.187        &       -0.001    &        0.003     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 519.234 & \\textbf{  Durbin-Watson:     } &     2.034  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 16505.757  \\\\\n",
       "\\textbf{Skew:}          &  -0.005 & \\textbf{  Prob(JB):          } &      0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  15.348 & \\textbf{  Cond. No.          } &  2.38e+15  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 8.16e-30. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.326\n",
       "Model:                            GLS   Adj. R-squared:                  0.325\n",
       "Method:                 Least Squares   F-statistic:                     251.0\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):          3.43e-219\n",
       "Time:                        21:07:36   Log-Likelihood:                 5953.5\n",
       "No. Observations:                2598   AIC:                        -1.189e+04\n",
       "Df Residuals:                    2592   BIC:                        -1.186e+04\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -0.0007      0.000     -2.061      0.039      -0.001   -3.57e-05\n",
       "STIR           0.8590      0.025     34.818      0.000       0.811       0.907\n",
       "d1            -0.0042      0.001     -4.838      0.000      -0.006      -0.002\n",
       "d2             0.0003      0.001      0.297      0.767      -0.001       0.002\n",
       "d3             0.0016      0.001      1.902      0.057   -5.06e-05       0.003\n",
       "d4             0.0004      0.001      0.477      0.634      -0.001       0.002\n",
       "d5             0.0011      0.001      1.319      0.187      -0.001       0.003\n",
       "==============================================================================\n",
       "Omnibus:                      519.234   Durbin-Watson:                   2.034\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16505.757\n",
       "Skew:                          -0.005   Prob(JB):                         0.00\n",
       "Kurtosis:                      15.348   Cond. No.                     2.38e+15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 8.16e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma4 = np.diag(np.array([1/np.sqrt(var_lsr) if i < len(y)/2 else 1/np.sqrt(var_ssr) for i in range(len(y))]))\n",
    "gls_model = sm.GLS(y, x2, sigma=sigma4)\n",
    "res = gls_model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c6e28-199c-4a9d-8c32-047d5de64469",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## method4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "70bfeac7-3408-449e-afd3-917bff2be64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>GLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.802</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>GLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.802</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1755.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 19 Feb 2024</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:48:28</td>     <th>  Log-Likelihood:    </th>  <td>  7859.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  2598</td>      <th>  AIC:               </th> <td>-1.570e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  2591</td>      <th>  BIC:               </th> <td>-1.566e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>-8.753e+07</td> <td> 1.89e+09</td> <td>   -0.046</td> <td> 0.963</td> <td> -3.8e+09</td> <td> 3.62e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STIR</th>  <td>    0.9181</td> <td>    0.009</td> <td>  101.286</td> <td> 0.000</td> <td>    0.900</td> <td>    0.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d1</th>    <td> 8.753e+07</td> <td> 1.89e+09</td> <td>    0.046</td> <td> 0.963</td> <td>-3.62e+09</td> <td>  3.8e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d2</th>    <td> 8.753e+07</td> <td> 1.89e+09</td> <td>    0.046</td> <td> 0.963</td> <td>-3.62e+09</td> <td>  3.8e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d3</th>    <td> 8.753e+07</td> <td> 1.89e+09</td> <td>    0.046</td> <td> 0.963</td> <td>-3.62e+09</td> <td>  3.8e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d4</th>    <td> 8.753e+07</td> <td> 1.89e+09</td> <td>    0.046</td> <td> 0.963</td> <td>-3.62e+09</td> <td>  3.8e+09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>d5</th>    <td> 8.753e+07</td> <td> 1.89e+09</td> <td>    0.046</td> <td> 0.963</td> <td>-3.62e+09</td> <td>  3.8e+09</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>247.317</td> <th>  Durbin-Watson:     </th> <td>   1.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1708.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.109</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.967</td>  <th>  Cond. No.          </th> <td>3.28e+13</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.71e-20. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.802   \\\\\n",
       "\\textbf{Model:}            &       GLS        & \\textbf{  Adj. R-squared:    } &     0.802   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     1755.   \\\\\n",
       "\\textbf{Date:}             & Mon, 19 Feb 2024 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n",
       "\\textbf{Time:}             &     20:48:28     & \\textbf{  Log-Likelihood:    } &    7859.2   \\\\\n",
       "\\textbf{No. Observations:} &        2598      & \\textbf{  AIC:               } & -1.570e+04  \\\\\n",
       "\\textbf{Df Residuals:}     &        2591      & \\textbf{  BIC:               } & -1.566e+04  \\\\\n",
       "\\textbf{Df Model:}         &           6      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &   -8.753e+07  &     1.89e+09     &    -0.046  &         0.963        &     -3.8e+09    &     3.62e+09     \\\\\n",
       "\\textbf{STIR}  &       0.9181  &        0.009     &   101.286  &         0.000        &        0.900    &        0.936     \\\\\n",
       "\\textbf{d1}    &    8.753e+07  &     1.89e+09     &     0.046  &         0.963        &    -3.62e+09    &      3.8e+09     \\\\\n",
       "\\textbf{d2}    &    8.753e+07  &     1.89e+09     &     0.046  &         0.963        &    -3.62e+09    &      3.8e+09     \\\\\n",
       "\\textbf{d3}    &    8.753e+07  &     1.89e+09     &     0.046  &         0.963        &    -3.62e+09    &      3.8e+09     \\\\\n",
       "\\textbf{d4}    &    8.753e+07  &     1.89e+09     &     0.046  &         0.963        &    -3.62e+09    &      3.8e+09     \\\\\n",
       "\\textbf{d5}    &    8.753e+07  &     1.89e+09     &     0.046  &         0.963        &    -3.62e+09    &      3.8e+09     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 247.317 & \\textbf{  Durbin-Watson:     } &    1.971  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 1708.380  \\\\\n",
       "\\textbf{Skew:}          &   0.109 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &   6.967 & \\textbf{  Cond. No.          } & 3.28e+13  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{GLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The smallest eigenvalue is 4.71e-20. This might indicate that there are \\newline\n",
       " strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            GLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.802\n",
       "Model:                            GLS   Adj. R-squared:                  0.802\n",
       "Method:                 Least Squares   F-statistic:                     1755.\n",
       "Date:                Mon, 19 Feb 2024   Prob (F-statistic):               0.00\n",
       "Time:                        20:48:28   Log-Likelihood:                 7859.2\n",
       "No. Observations:                2598   AIC:                        -1.570e+04\n",
       "Df Residuals:                    2591   BIC:                        -1.566e+04\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const      -8.753e+07   1.89e+09     -0.046      0.963    -3.8e+09    3.62e+09\n",
       "STIR           0.9181      0.009    101.286      0.000       0.900       0.936\n",
       "d1          8.753e+07   1.89e+09      0.046      0.963   -3.62e+09     3.8e+09\n",
       "d2          8.753e+07   1.89e+09      0.046      0.963   -3.62e+09     3.8e+09\n",
       "d3          8.753e+07   1.89e+09      0.046      0.963   -3.62e+09     3.8e+09\n",
       "d4          8.753e+07   1.89e+09      0.046      0.963   -3.62e+09     3.8e+09\n",
       "d5          8.753e+07   1.89e+09      0.046      0.963   -3.62e+09     3.8e+09\n",
       "==============================================================================\n",
       "Omnibus:                      247.317   Durbin-Watson:                   1.971\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1708.380\n",
       "Skew:                           0.109   Prob(JB):                         0.00\n",
       "Kurtosis:                       6.967   Cond. No.                     3.28e+13\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.71e-20. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma4 = np.diag(np.array([var_lsr if i < len(y)/2 else var_ssr for i in range(len(y))]))\n",
    "gls_model = sm.GLS(y, x2, sigma=sigma4)\n",
    "res = gls_model.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c526c1a-9dc3-4b42-bfd1-6e26969debc4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254f01a-5a6f-46c0-87d7-6b5e02f42a1c",
   "metadata": {},
   "source": [
    "Suppose we find the fitted residuals in the GLS regression in Q3. What are the Breusch-Pagan chi-square test statistic value and the White's Heteroskedasticity chi-square test statistic value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd5ee01-8174-411e-9cd1-e7f7d03abeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6745240798849945"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "bp_test = het_breuschpagan(res.resid ** 2, sm.add_constant(x2))\n",
    "bp_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d98e015-5ff8-478f-a18a-d8783bb5fab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.190449008136973"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "wh_test = het_white(res.resid ** 2, sm.add_constant(x2))\n",
    "wh_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a6dcc5-9a6b-4798-b614-dda032082e35",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88065982-6e50-46e3-851d-df5f9352ad79",
   "metadata": {},
   "source": [
    "In the OLS regression of dependent variable LSR on explanatory variables STIR and the 5 dummy variables, suppose the fitted residuals indicate significantly positive autocorrelations. Perform a GLS regression to improve on the estimates. Report the OLS Durbin-Watson statistic and the GLS Durbin-Watson statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2723a6de-7c9a-45c4-9eb5-efc405074a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6916522439077524\n",
      "0.09095270202736264\n",
      "0.04694953172306796\n"
     ]
    }
   ],
   "source": [
    "resid_fit = sm.OLS(\n",
    "    np.asarray(result1.resid)[1:], sm.add_constant(np.asarray(result1.resid)[:-1])\n",
    ").fit()\n",
    "print(resid_fit.tvalues[1])\n",
    "print(resid_fit.pvalues[1])\n",
    "rho = resid_fit.params[1]\n",
    "print(rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cfd8e1-2f78-4c69-a6cf-a345748d9a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import toeplitz\n",
    "trix = toeplitz(range(len(result1.resid))) ### trix is sq matrix with zero in diag, 1 in first off diag, 2 in 2nd off diag, etc.\n",
    "sigma = rho ** trix ### this is cov matrix of residuals except the factor of sigma_u^2 is left out\n",
    "gls_model = sm.GLS(data['LSR'], x, sigma=sigma)\n",
    "gls_results = gls_model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b959c5-94a1-4229-95e8-b818e2aeaff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    LSR   R-squared:                       0.886\n",
      "Model:                            GLS   Adj. R-squared:                  0.886\n",
      "Method:                 Least Squares   F-statistic:                     2009.\n",
      "Date:                Mon, 19 Feb 2024   Prob (F-statistic):               0.00\n",
      "Time:                        17:26:31   Log-Likelihood:                 4868.3\n",
      "No. Observations:                1299   AIC:                            -9725.\n",
      "Df Residuals:                    1293   BIC:                            -9694.\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "STIR           0.9222      0.009    100.117      0.000       0.904       0.940\n",
      "d1             0.0003      0.000      0.749      0.454      -0.000       0.001\n",
      "d2             0.0008      0.000      2.145      0.032    6.51e-05       0.001\n",
      "d3          7.044e-05      0.000      0.198      0.843      -0.001       0.001\n",
      "d4            -0.0001      0.000     -0.388      0.698      -0.001       0.001\n",
      "d5            -0.0002      0.000     -0.468      0.640      -0.001       0.001\n",
      "==============================================================================\n",
      "Omnibus:                      100.866   Durbin-Watson:                   1.997\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              454.999\n",
      "Skew:                           0.195   Prob(JB):                     1.58e-99\n",
      "Kurtosis:                       5.873   Cond. No.                         27.0\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(gls_results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5178274-a726-46a1-918b-b0b9287f3f42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
